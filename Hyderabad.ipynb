{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32dd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install selenium webdriver-manager\n",
    "\n",
    "# import os, json, time, re, datetime\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.common.exceptions import ElementClickInterceptedException, TimeoutException\n",
    "# from webdriver_manager.chrome import ChromeDriverManager\n",
    "# BASE_URL = \"https://cases.shc.gov.pk/\"\n",
    "# COURT_NAME = \"Hyderabad\"\n",
    "# COURT_VALUE = \"2\"\n",
    "# BENCH_TEXT  = \"Circuit Court Hyderabad\"\n",
    "# OUTPUT_FILE = \"SindhCourt_Hyderabad.json\"\n",
    "\n",
    "# def make_driver(headless=True):\n",
    "#     from selenium.webdriver.chrome.options import Options\n",
    "#     opts = Options()\n",
    "#     if headless:\n",
    "#         opts.add_argument(\"--headless=new\")\n",
    "#     opts.add_argument(\"--start-maximized\")\n",
    "#     opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "#     opts.add_argument(\"--no-sandbox\")\n",
    "#     opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "#     return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)\n",
    "\n",
    "# def W(d, t=20): return WebDriverWait(d, t)\n",
    "\n",
    "# # -------------------- helpers: robust Karachi tile click --------------------\n",
    "# def safe_click(driver, el):\n",
    "#     try:\n",
    "#         driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", el)\n",
    "#         time.sleep(0.1)\n",
    "#         try:\n",
    "#             el.click()\n",
    "#         except ElementClickInterceptedException:\n",
    "#             driver.execute_script(\"arguments[0].click();\", el)\n",
    "#     except Exception:\n",
    "#         driver.execute_script(\"arguments[0].click();\", el)\n",
    "\n",
    "# def open_court_bench(driver):\n",
    "#     W(driver).until(EC.presence_of_all_elements_located(\n",
    "#         (By.CSS_SELECTOR, \"button.btn.btn-dark.btn-sm.btn-block.mt-2.stretched-link\")\n",
    "#     ))\n",
    "#     locators = [\n",
    "#         (By.XPATH, f\"//div[.//a[contains(.,'{BENCH_TEXT}')]]//button[contains(@class,'stretched-link')]\"),\n",
    "#         (By.XPATH, f\"//div[contains(@class,'card') or contains(@class,'col')]//a[contains(.,'{BENCH_TEXT}')]/following::button[contains(@class,'stretched-link')][1]\"),\n",
    "#         (By.XPATH, \"//button[contains(@class,'stretched-link')]\"),\n",
    "#     ]\n",
    "\n",
    "#     for by, value in locators:\n",
    "#         try:\n",
    "#             btn = driver.find_element(by, value)\n",
    "#             btn.click()\n",
    "#             return\n",
    "#         except:\n",
    "#             continue\n",
    "#     raise Exception(f\"Bench button not found for: {BENCH_TEXT}\")\n",
    "# # -------------------- search form --------------------\n",
    "# def set_status_all(driver):\n",
    "#     try:\n",
    "#         all_radio = driver.find_element(By.CSS_SELECTOR,\n",
    "#             \"input[type='radio'][name='CasesSearch[isPending]'][value='3']\")\n",
    "#         driver.execute_script(\"arguments[0].click()\", all_radio)\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "# def select_karachi_and_search(driver):\n",
    "#     sel = Select(W(driver).until(EC.presence_of_element_located((By.ID, \"casessearch-circuitcode\"))))\n",
    "#     sel.select_by_value(COURT_VALUE)  # Karachi\n",
    "#     set_status_all(driver)\n",
    "#     W(driver).until(EC.element_to_be_clickable((By.ID, \"submit_search\"))).click()\n",
    "\n",
    "# def wait_for_table(driver):\n",
    "#     W(driver).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table.kv-grid-table\")))\n",
    "#     W(driver).until(lambda d: len(d.find_elements(By.CSS_SELECTOR, \"table.kv-grid-table tbody tr.crud-datatable\")) > 0)\n",
    "\n",
    "# # -------------------- list page parsing --------------------\n",
    "# def parse_page(driver):\n",
    "#     ths = driver.find_elements(By.CSS_SELECTOR, \"table.kv-grid-table thead th\")\n",
    "#     headers = []\n",
    "#     for th in ths:\n",
    "#         label = th.text.strip()\n",
    "#         if not label or label in (\"#\", \"Actions\"):\n",
    "#             continue\n",
    "#         headers.append(label)\n",
    "\n",
    "#     rows = driver.find_elements(By.CSS_SELECTOR, \"table.kv-grid-table tbody tr.crud-datatable\")\n",
    "#     page_data = []\n",
    "\n",
    "#     for r in rows:\n",
    "#         tds_all = r.find_elements(By.CSS_SELECTOR, \"td.crud-datatable\")\n",
    "#         cells = []\n",
    "#         for td in tds_all:\n",
    "#             if \"skip-export\" in (td.get_attribute(\"class\") or \"\").lower():\n",
    "#                 continue\n",
    "#             cells.append(td.text.strip())\n",
    "\n",
    "#         cells = cells[:len(headers)]\n",
    "#         header_map = {h.lower(): cells[i] if i < len(cells) else \"NA\" for i, h in enumerate(headers)}\n",
    "#         def get(h): return header_map.get(h.lower(), \"NA\")\n",
    "\n",
    "#         rec = {\n",
    "#             \"CaseName\":     get(\"Case Name\"),\n",
    "#             \"Caseno\":       get(\"Caseno\"),\n",
    "#             \"Caseyear\":     get(\"Caseyear\"),\n",
    "#             \"Bench\":        COURT_NAME,\n",
    "#             \"Circuitcode\":  get(\"Circuitcode\") or COURT_NAME,\n",
    "#             \"CaseTitle\":    get(\"CASE TITLE\"),\n",
    "#             \"Matter\":       get(\"Matter\"),\n",
    "#             \"LastHearing\":  get(\"Last Hearing\"),\n",
    "#             \"NextDate\":     get(\"Next Date\"),\n",
    "#             \"DisposalDate\": get(\"Disposal Date\"),\n",
    "#             \"Status\":       get(\"Status\"),\n",
    "#         }\n",
    "#         if isinstance(rec[\"Caseyear\"], str):\n",
    "#             m = re.search(r\"\\d{4}\", rec[\"Caseyear\"])\n",
    "#             if m: rec[\"Caseyear\"] = int(m.group(0))\n",
    "\n",
    "#         href = None\n",
    "#         try:\n",
    "#             href = r.find_element(By.CSS_SELECTOR, \"td.skip-export a.btn.btn-primary\").get_attribute(\"href\")\n",
    "#         except Exception:\n",
    "#             pass\n",
    "#         rec[\"_detail_href\"] = href\n",
    "#         page_data.append(rec)\n",
    "\n",
    "#     return page_data\n",
    "\n",
    "# # -------------------- existing profile/parties/advocates functions (no change) --------------------\n",
    "# # ... [keep your scrape_case_profile, scrape_parties_only, scrape_advocates_only, etc. as in your script] ...\n",
    "# # -------------------- CASE PROFILE ONLY (detail page) --------------------\n",
    "# def extract_inst_disp_cell(driver):\n",
    "#     cell = W(driver).until(EC.presence_of_element_located((\n",
    "#         By.XPATH,\n",
    "#         \"//table[@id='w1']//table[contains(@class,'kv-child-table')]\"\n",
    "#         \"//th[contains(normalize-space(.), 'Institution / Admit Date')]/following-sibling::td[1]\"\n",
    "#     )))\n",
    "#     raw = cell.text.strip()\n",
    "#     dates = re.findall(r\"\\b\\d{2}-[A-Z]{3}-\\d{2,4}\\b\", raw)\n",
    "#     inst = dates[0] if len(dates) >= 1 else \"NA\"\n",
    "#     disp = dates[1] if len(dates) >= 2 else \"NA\"\n",
    "#     cons = dates[2] if len(dates) >= 3 else \"NA\"\n",
    "#     m = re.search(r\"\\(([^)]+)\\)\", raw)\n",
    "#     note = m.group(1).strip() if m else \"NA\"\n",
    "#     return {\n",
    "#         \"institution_admit_date\": inst,\n",
    "#         \"disposal_date\": disp,\n",
    "#         \"consigned_date\": cons,\n",
    "#         \"disposal_note\": note\n",
    "#     }\n",
    "\n",
    "# def extract_last_hearing_detail(driver):\n",
    "#     cell = W(driver).until(EC.presence_of_element_located((\n",
    "#         By.XPATH,\n",
    "#         \"//table[@id='w1']//table[contains(@class,'kv-child-table')]\"\n",
    "#         \"//th[normalize-space(.)='Last Hearing Detail']/following-sibling::td[1]\"\n",
    "#     )))\n",
    "#     lines = [ln.strip() for ln in cell.text.splitlines() if ln.strip()]\n",
    "#     def val_after(prefix):\n",
    "#         for ln in lines:\n",
    "#             if ln.lower().startswith(prefix.lower()+\":\"):\n",
    "#                 return ln.split(\":\",1)[1].strip() or \"NA\"\n",
    "#         return \"NA\"\n",
    "#     return {\n",
    "#         \"date\":    val_after(\"Date\"),\n",
    "#         \"list\":    val_after(\"List\"),\n",
    "#         \"stage\":   val_after(\"Stage\"),\n",
    "#         \"bench\":   val_after(\"Bench\"),\n",
    "#         \"remarks\": val_after(\"Other Info\"),\n",
    "#     }\n",
    "\n",
    "# def scrape_case_profile(driver, href):\n",
    "#     default = {\n",
    "#         \"profile\": {\"institution_admit_date\":\"NA\",\"disposal_date\":\"NA\",\"consigned_date\":\"NA\",\"disposal_note\":\"NA\"},\n",
    "#         \"last_hearing\": {\"date\":\"NA\",\"list\":\"NA\",\"stage\":\"NA\",\"bench\":\"NA\",\"remarks\":\"NA\"}\n",
    "#     }\n",
    "#     if not href:\n",
    "#         return default\n",
    "\n",
    "#     main = driver.current_window_handle\n",
    "#     driver.execute_script(\"window.open(arguments[0], '_blank');\", href)\n",
    "#     W(driver).until(lambda d: len(d.window_handles) > 1)\n",
    "#     detail = [h for h in driver.window_handles if h != main][0]\n",
    "#     driver.switch_to.window(detail)\n",
    "\n",
    "#     try:\n",
    "#         profile = extract_inst_disp_cell(driver)\n",
    "#         last    = extract_last_hearing_detail(driver)\n",
    "#         return {\"profile\": profile, \"last_hearing\": last}\n",
    "#     except Exception:\n",
    "#         return default\n",
    "#     finally:\n",
    "#         driver.close()\n",
    "#         driver.switch_to.window(main)\n",
    "# # -------------------- PARTIES ONLY (open/close in its own pass) --------------------\n",
    "# def click_tab_and_wait_pane(driver, tab_text):\n",
    "#     a = W(driver, 12).until(EC.element_to_be_clickable(\n",
    "#         (By.XPATH, f\"//ul[contains(@class,'nav-tabs')]//a[normalize-space()='{tab_text}']\")))\n",
    "#     href = a.get_attribute(\"href\") or \"\"\n",
    "#     target_id = a.get_attribute(\"aria-controls\") or (href.split(\"#\",1)[1] if \"#\" in href else None)\n",
    "#     try:\n",
    "#         a.click()\n",
    "#     except Exception:\n",
    "#         driver.execute_script(\"arguments[0].click();\", a)\n",
    "\n",
    "#     if not target_id:\n",
    "#         pane = W(driver, 12).until(EC.presence_of_element_located(\n",
    "#             (By.XPATH, \"//div[@class='tab-content']//div[contains(@class,'active')]\")))\n",
    "#     else:\n",
    "#         pane = W(driver, 12).until(EC.presence_of_element_located((By.ID, target_id)))\n",
    "\n",
    "#     def pane_ready(_):\n",
    "#         cls = pane.get_attribute(\"class\") or \"\"\n",
    "#         if \"active\" not in cls:\n",
    "#             return False\n",
    "#         if pane.find_elements(By.CSS_SELECTOR, \"table.kv-grid-table tbody tr.crud-datatable\"):\n",
    "#             return True\n",
    "#         if pane.find_elements(By.CSS_SELECTOR, \"div.empty\"):\n",
    "#             return True\n",
    "#         return False\n",
    "\n",
    "#     W(driver, 12).until(pane_ready)\n",
    "#     return pane\n",
    "\n",
    "# def extract_parties_from_pane(pane):\n",
    "#     rows = pane.find_elements(By.CSS_SELECTOR, \"table.kv-grid-table tbody tr.crud-datatable\")\n",
    "#     out = []\n",
    "#     for r in rows:\n",
    "#         try:\n",
    "#             num_el = r.find_element(By.CSS_SELECTOR, \"td[data-col-seq='0']\")\n",
    "#             name_el = r.find_element(By.CSS_SELECTOR, \"td[data-col-seq='1']\")\n",
    "#         except Exception:\n",
    "#             tds = r.find_elements(By.CSS_SELECTOR, \"td\")\n",
    "#             if len(tds) >= 2:\n",
    "#                 num_el, name_el = tds[0], tds[1]\n",
    "#             else:\n",
    "#                 continue\n",
    "#         out.append({\n",
    "#             \"party_no\": (num_el.text or \"\").strip() or \"NA\",\n",
    "#             \"name\":     (name_el.text or \"\").strip() or \"NA\"\n",
    "#         })\n",
    "#     return out\n",
    "\n",
    "# def scrape_parties_only(driver, href):\n",
    "#     if not href:\n",
    "#         return []\n",
    "#     main = driver.current_window_handle\n",
    "#     driver.execute_script(\"window.open(arguments[0], '_blank');\", href)\n",
    "#     W(driver).until(lambda d: len(d.window_handles) > 1)\n",
    "#     detail = [h for h in driver.window_handles if h != main][0]\n",
    "#     driver.switch_to.window(detail)\n",
    "#     try:\n",
    "#         pane = click_tab_and_wait_pane(driver, \"Parties Details\")\n",
    "#         return extract_parties_from_pane(pane)\n",
    "#     except Exception:\n",
    "#         return []\n",
    "#     finally:\n",
    "#         driver.close()\n",
    "#         driver.switch_to.window(main)\n",
    "# # -------------------- ADVOCATES ONLY (open/close in its own pass) --------------------\n",
    "# def parse_adv_rows(rows):\n",
    "#     out = []\n",
    "#     for r in rows:\n",
    "#         tds = r.find_elements(By.TAG_NAME, \"td\")\n",
    "#         if len(tds) < 2:   # 'No results found.' (single td with colspan)\n",
    "#             continue\n",
    "#         name_cell = (tds[0].text or \"\").strip()\n",
    "#         date_cell = (tds[1].text or \"\").strip()\n",
    "#         m = re.search(r\"\\((ADVO-[^)]+)\\)\", name_cell, flags=re.I)\n",
    "#         ledger = m.group(1) if m else \"NA\"\n",
    "#         name = re.sub(r\"\\s*\\(ADVO-[^)]+\\)\\s*$\", \"\", name_cell, flags=re.I).strip()\n",
    "#         out.append({\n",
    "#             \"name\": name or \"NA\",\n",
    "#             \"ledger_no\": ledger,\n",
    "#             \"entry_date\": (date_cell if date_cell and date_cell.lower() != \"(not set)\" else \"NA\"),\n",
    "#         })\n",
    "#     return out\n",
    "\n",
    "# def extract_advocates_from_pane(pane):\n",
    "#     applicant_rows  = pane.find_elements(By.XPATH, \".//div[contains(@class,'panel')][contains(.,'Advocate for Applicant')]//table[contains(@class,'kv-grid-table')]//tbody//tr\")\n",
    "#     respondent_rows = pane.find_elements(By.XPATH, \".//div[contains(@class,'panel')][contains(.,'Advocate for Respondent')]//table[contains(@class,'kv-grid-table')]//tbody//tr\")\n",
    "#     return {\n",
    "#         \"applicant\": parse_adv_rows(applicant_rows),\n",
    "#         \"respondent\": parse_adv_rows(respondent_rows)\n",
    "#     }\n",
    "\n",
    "# def scrape_advocates_only(driver, href):\n",
    "#     if not href:\n",
    "#         return {\"applicant\": [], \"respondent\": []}\n",
    "#     main = driver.current_window_handle\n",
    "#     driver.execute_script(\"window.open(arguments[0], '_blank');\", href)\n",
    "#     W(driver).until(lambda d: len(d.window_handles) > 1)\n",
    "#     detail = [h for h in driver.window_handles if h != main][0]\n",
    "#     driver.switch_to.window(detail)\n",
    "#     try:\n",
    "#         pane = click_tab_and_wait_pane(driver, \"Case Advocates\")\n",
    "#         return extract_advocates_from_pane(pane)\n",
    "#     except Exception:\n",
    "#         return {\"applicant\": [], \"respondent\": []}\n",
    "#     finally:\n",
    "#         driver.close()\n",
    "#         driver.switch_to.window(main)\n",
    "\n",
    "# # -------------------- pagination --------------------\n",
    "# def go_next_page(driver, current_page_idx):\n",
    "#     pagers = driver.find_elements(By.CSS_SELECTOR, \"ul.pagination\")\n",
    "#     if not pagers: return False\n",
    "#     pager = pagers[0]\n",
    "#     next_li = pager.find_elements(By.CSS_SELECTOR, \"li.next\")\n",
    "#     if not next_li: return False\n",
    "#     next_li = next_li[0]\n",
    "#     cls = (next_li.get_attribute(\"class\") or \"\").lower()\n",
    "#     link = next_li.find_elements(By.CSS_SELECTOR, \"a\")\n",
    "#     if \"disabled\" in cls or not link:\n",
    "#         return False\n",
    "\n",
    "#     try:\n",
    "#         first_before = driver.find_element(By.CSS_SELECTOR,\n",
    "#             \"table.kv-grid-table tbody tr.crud-datatable td.crud-datatable\").text\n",
    "#     except Exception:\n",
    "#         first_before = \"\"\n",
    "\n",
    "#     driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", link[0])\n",
    "#     driver.execute_script(\"arguments[0].click();\", link[0])\n",
    "\n",
    "#     def changed(d):\n",
    "#         try:\n",
    "#             new_first = d.find_element(By.CSS_SELECTOR,\n",
    "#                 \"table.kv-grid-table tbody tr.crud-datatable td.crud-datatable\").text\n",
    "#             if new_first != first_before:\n",
    "#                 return True\n",
    "#         except Exception:\n",
    "#             pass\n",
    "#         try:\n",
    "#             actives = d.find_elements(By.CSS_SELECTOR, \"ul.pagination li.active\")\n",
    "#             if actives and actives[0].text.strip() != str(current_page_idx):\n",
    "#                 return True\n",
    "#         except Exception:\n",
    "#             pass\n",
    "#         return False\n",
    "\n",
    "#     WebDriverWait(driver, 20).until(changed)\n",
    "#     time.sleep(0.3)\n",
    "#     return True\n",
    "\n",
    "# # -------------------- pagination --------------------\n",
    "# def go_next_page(driver, current_page_idx):\n",
    "#     pagers = driver.find_elements(By.CSS_SELECTOR, \"ul.pagination\")\n",
    "#     if not pagers: return False\n",
    "#     pager = pagers[0]\n",
    "#     next_li = pager.find_elements(By.CSS_SELECTOR, \"li.next\")\n",
    "#     if not next_li: return False\n",
    "#     next_li = next_li[0]\n",
    "#     cls = (next_li.get_attribute(\"class\") or \"\").lower()\n",
    "#     link = next_li.find_elements(By.CSS_SELECTOR, \"a\")\n",
    "#     if \"disabled\" in cls or not link:\n",
    "#         return False\n",
    "\n",
    "#     try:\n",
    "#         first_before = driver.find_element(By.CSS_SELECTOR,\n",
    "#             \"table.kv-grid-table tbody tr.crud-datatable td.crud-datatable\").text\n",
    "#     except Exception:\n",
    "#         first_before = \"\"\n",
    "\n",
    "#     driver.execute_script(\"arguments[0].scrollIntoView({block:'center'});\", link[0])\n",
    "#     driver.execute_script(\"arguments[0].click();\", link[0])\n",
    "\n",
    "#     def changed(d):\n",
    "#         try:\n",
    "#             new_first = d.find_element(By.CSS_SELECTOR,\n",
    "#                 \"table.kv-grid-table tbody tr.crud-datatable td.crud-datatable\").text\n",
    "#             if new_first != first_before:\n",
    "#                 return True\n",
    "#         except Exception:\n",
    "#             pass\n",
    "#         try:\n",
    "#             actives = d.find_elements(By.CSS_SELECTOR, \"ul.pagination li.active\")\n",
    "#             if actives and actives[0].text.strip() != str(current_page_idx):\n",
    "#                 return True\n",
    "#         except Exception:\n",
    "#             pass\n",
    "#         return False\n",
    "\n",
    "#     WebDriverWait(driver, 20).until(changed)\n",
    "#     time.sleep(0.3)\n",
    "#     return True\n",
    "\n",
    "# # -------------------- JSON writer --------------------\n",
    "# def init_or_load_payload():\n",
    "#     if os.path.exists(OUTPUT_FILE):\n",
    "#         try:\n",
    "#             with open(OUTPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "#                 payload = json.load(f)\n",
    "#             if not isinstance(payload, dict) or \"cases\" not in payload:\n",
    "#                 raise ValueError()\n",
    "#             return payload\n",
    "#         except Exception:\n",
    "#             pass\n",
    "#     return {\n",
    "#         \"metadata\": {\n",
    "#             \"file_name\": os.path.basename(OUTPUT_FILE),\n",
    "#             \"created_on\": datetime.date.today().strftime(\"%Y-%m-%d\"),\n",
    "#             \"bench\": COURT_NAME,\n",
    "#             \"source\": \"Sindh High Court Case Search Portal\",\n",
    "#             \"url\": BASE_URL,\n",
    "#             \"description\": \"Sindh High Court case metadata (Case Profile + Parties + Advocates).\"\n",
    "#         },\n",
    "#         \"cases\": []\n",
    "#     }\n",
    "\n",
    "# def save_payload(payload):\n",
    "#     with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# # -------------------- RUN --------------------\n",
    "# driver = make_driver(headless=True)  # set True if you prefer headless\n",
    "# driver.get(BASE_URL)\n",
    "\n",
    "# open_court_bench(driver)\n",
    "# select_karachi_and_search(driver)\n",
    "# wait_for_table(driver)\n",
    "\n",
    "# payload = init_or_load_payload()\n",
    "# page = 1\n",
    "# srno = len(payload[\"cases\"]) + 1   ### NEW ### start where last run left off\n",
    "\n",
    "# while True:\n",
    "#     rows = parse_page(driver)\n",
    "\n",
    "#     for rec in rows:\n",
    "#         href = rec.get(\"_detail_href\")\n",
    "\n",
    "#         # 1) Profile visit\n",
    "#         prof = scrape_case_profile(driver, href)\n",
    "\n",
    "#         # 2) Parties visit\n",
    "#         parties = scrape_parties_only(driver, href)\n",
    "\n",
    "#         # 3) Advocates visit\n",
    "#         advocates = scrape_advocates_only(driver, href)\n",
    "\n",
    "#         rec.pop(\"_detail_href\", None)\n",
    "#         rec[\"SrNo\"] = srno             ### NEW ###\n",
    "#         rec[\"Details\"] = {**prof, \"parties\": parties, \"advocates\": advocates}\n",
    "\n",
    "#         payload[\"cases\"].append(rec)\n",
    "#         save_payload(payload)\n",
    "#         print(f\"saved case {srno}: {rec.get('CaseName','')} / {rec.get('Caseno','')}\")\n",
    "\n",
    "#         srno += 1   ### NEW ### increment after each case\n",
    "\n",
    "#     if not go_next_page(driver, page):\n",
    "#         break\n",
    "#     page += 1\n",
    "\n",
    "# driver.quit()\n",
    "# print(f\"Done. Total cases saved: {len(payload['cases'])} -> {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400c11d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "open_court_bench() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 95\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m scrape_one_case(href, summary)\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# ----------------- How to run -----------------\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# 1) Collect listing rows fast\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m rows = \u001b[43mcollect_list_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_pages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# or a number while testing\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# 2) Parallel detail scraping\u001b[39;00m\n\u001b[32m     98\u001b[39m scrape_details_in_parallel(\n\u001b[32m     99\u001b[39m     records=rows,\n\u001b[32m    100\u001b[39m     output_path=OUTPUT_FILE,\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m     RATE_SLEEP=\u001b[32m0.25\u001b[39m       \u001b[38;5;66;03m# throttle process start rate\u001b[39;00m\n\u001b[32m    104\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcollect_list_records\u001b[39m\u001b[34m(max_pages)\u001b[39m\n\u001b[32m      3\u001b[39m driver = make_driver(headless=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m driver.get(BASE_URL)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mopen_court_bench\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBENCH_TEXT\u001b[49m\u001b[43m)\u001b[49m            \u001b[38;5;66;03m# or open_court_bench(driver,\"Circuit Court Hyderabad\")\u001b[39;00m\n\u001b[32m      6\u001b[39m select_karachi_and_search(driver)               \u001b[38;5;66;03m# OR your select_* for that bench value\u001b[39;00m\n\u001b[32m      7\u001b[39m wait_for_table(driver)\n",
      "\u001b[31mTypeError\u001b[39m: open_court_bench() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# ---- Pass 1: collect hrefs quickly (single driver) -----------------\n",
    "def collect_list_records(max_pages=None):\n",
    "    driver = make_driver(headless=True)\n",
    "    driver.get(BASE_URL)\n",
    "    open_court_bench(driver, BENCH_TEXT)            # or open_court_bench(driver,\"Circuit Court Hyderabad\")\n",
    "    select_karachi_and_search(driver)               # OR your select_* for that bench value\n",
    "    wait_for_table(driver)\n",
    "\n",
    "    records = []   # [{'summary': rec, 'href': url}, ...]\n",
    "    page = 1\n",
    "    while True:\n",
    "        for rec in parse_page(driver):\n",
    "            href = rec.pop(\"_detail_href\", None)\n",
    "            if href:\n",
    "                records.append({\"summary\": rec, \"href\": href})\n",
    "        if max_pages and page >= max_pages:\n",
    "            break\n",
    "        if not go_next_page(driver, page):\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    driver.quit()\n",
    "    return records\n",
    "\n",
    "# ---- Pass 2: parallel detail scraping ------------------------------\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def scrape_one_case(href, summary):\n",
    "    \"\"\"Runs in a worker process; creates and destroys its own driver.\"\"\"\n",
    "    d = make_driver(headless=True)\n",
    "    d.get(BASE_URL)   # required so window.open() has a valid context\n",
    "\n",
    "    # Reuse your detail functions exactly as-is:\n",
    "    prof = scrape_case_profile(d, href)\n",
    "    parties = scrape_parties_only(d, href)\n",
    "    adv = scrape_advocates_only(d, href)\n",
    "\n",
    "    d.quit()\n",
    "    return {\n",
    "        **summary,\n",
    "        \"Details\": {**prof, \"parties\": parties, \"advocates\": adv}\n",
    "    }\n",
    "\n",
    "def scrape_details_in_parallel(records, output_path, start_sr=1, MAX_WORKERS=4, RATE_SLEEP=0.3):\n",
    "    \"\"\"\n",
    "    records: [{'summary': {...}, 'href': '...'}, ...] from collect_list_records\n",
    "    Writes one growing JSON file for resilience.\n",
    "    \"\"\"\n",
    "    # load or init output payload\n",
    "    if os.path.exists(output_path):\n",
    "        with open(output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            payload = json.load(f)\n",
    "    else:\n",
    "        payload = {\n",
    "            \"metadata\": {\n",
    "                \"file_name\": os.path.basename(output_path),\n",
    "                \"created_on\": datetime.date.today().strftime(\"%Y-%m-%d\"),\n",
    "                \"bench\": BENCH_TEXT,\n",
    "                \"source\": \"Sindh High Court Case Search Portal\",\n",
    "                \"url\": BASE_URL,\n",
    "                \"description\": \"Parallel scrape of case details.\"\n",
    "            },\n",
    "            \"cases\": []\n",
    "        }\n",
    "\n",
    "    sr = start_sr if payload[\"cases\"] == [] else len(payload[\"cases\"]) + 1\n",
    "\n",
    "    # fan out\n",
    "    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        futures = []\n",
    "        for item in records:\n",
    "            # small spacing to avoid launching too many at once\n",
    "            time.sleep(RATE_SLEEP)\n",
    "            # ensure we pass only serializable args\n",
    "            futures.append(ex.submit(sanitize_worker_call, item[\"href\"], item[\"summary\"]))\n",
    "\n",
    "        for fut in as_completed(futures):\n",
    "            try:\n",
    "                case = fut.result()\n",
    "                case[\"SrNo\"] = sr\n",
    "                payload[\"cases\"].append(case)\n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "                sr += 1\n",
    "                print(f\"saved #{sr-1}: {case.get('CaseName','')} / {case.get('Caseno','')}\")\n",
    "            except Exception as e:\n",
    "                print(\"worker failed:\", e)\n",
    "\n",
    "# Wrapper because ProcessPool needs top-level picklable callables\n",
    "def sanitize_worker_call(href, summary):\n",
    "    return scrape_one_case(href, summary)\n",
    "\n",
    "# ----------------- How to run -----------------\n",
    "# 1) Collect listing rows fast\n",
    "rows = collect_list_records(max_pages=None)   # or a number while testing\n",
    "\n",
    "# 2) Parallel detail scraping\n",
    "scrape_details_in_parallel(\n",
    "    records=rows,\n",
    "    output_path=OUTPUT_FILE,\n",
    "    start_sr=1,\n",
    "    MAX_WORKERS=3,        # 2â€“4 is usually safe\n",
    "    RATE_SLEEP=0.25       # throttle process start rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19c153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
